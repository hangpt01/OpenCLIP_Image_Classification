{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93928a80",
   "metadata": {},
   "source": [
    "Comparison of Zero-shot and Linear Probe Performance of Open CLIP-B-32 on CIFAR-10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f156c2",
   "metadata": {},
   "source": [
    "#### Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6f28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install open_clip_torch\n",
    "!pip install ftfy regex tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16300d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaipe/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cf2dac",
   "metadata": {},
   "source": [
    "#### Load CLIP ViT-B-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a64d78c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca1d7ca",
   "metadata": {},
   "source": [
    "A CLIP ViT-B/32 model trained with the LAION-2B English subset of LAION-5B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c8f5444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "## Load CLIP Model with pretrained weight from Laion2B\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k', device=device)\n",
    "\n",
    "\n",
    "#### Load CIFAR10 and create DataLoader\n",
    "root = os.path.expanduser(\"~/cache\")\n",
    "train_data = CIFAR10(root, download=True, train=True, transform=preprocess)\n",
    "test_data = CIFAR10(root, download=True, train=False, transform=preprocess)\n",
    "\n",
    "# Split the training dataset into 80% train and 20% validation (for Linear Probe Hyperparam Sweep)\n",
    "train_size = int(0.8 * len(train_data))  # 80% for training\n",
    "val_size = len(train_data) - train_size  # 20% for validation\n",
    "train_data, val_data = random_split(train_data, [train_size, val_size])\n",
    "\n",
    "batch_size = 2048\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f17304",
   "metadata": {},
   "source": [
    "### Linear Probe Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a85297",
   "metadata": {},
   "source": [
    "#### Get features from Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features and labels for Linear Probe (input (n_sample, dim))\n",
    "def get_features(dataset):\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(dataset, batch_size=batch_size)):\n",
    "            features = model.encode_image(images.to(device))\n",
    "\n",
    "            all_features.append(features)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    return torch.cat(all_features).cpu().numpy(), torch.cat(all_labels).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e859649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:29<00:00,  1.46s/it]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.27s/it]\n",
      "100%|██████████| 5/5 [00:06<00:00,  1.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# Linear Probe Data\n",
    "# Calculate features for train, validation, and test sets\n",
    "train_features, train_labels = get_features(train_data)\n",
    "val_features, val_labels = get_features(val_data)\n",
    "test_features, test_labels = get_features(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b54071",
   "metadata": {},
   "source": [
    "#### Run Sweep to get the best L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3958a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with C = 1e-06\n",
      "Validation Accuracy = 94.070%\n",
      "Training with C = 0.0001\n",
      "Validation Accuracy = 95.510%\n",
      "Training with C = 0.01\n",
      "Validation Accuracy = 96.790%\n",
      "Training with C = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaipe/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 96.630%\n",
      "Training with C = 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaipe/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 95.790%\n",
      "Training with C = 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaipe/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy = 95.730%\n",
      "Training with C = 1000000\n",
      "Validation Accuracy = 95.710%\n",
      "Best C value: 0.01 with validation accuracy of 96.790%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vaipe/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter sweep for regularization strength C (L2 regularization)\n",
    "C_values = [10**-6, 10**-4, 10**-2, 1, 10**2, 10**4, 10**6]  # Logarithmic sweep\n",
    "\n",
    "best_C = None\n",
    "best_accuracy = 0\n",
    "\n",
    "# Perform hyperparameter sweep over C\n",
    "for C in C_values:\n",
    "    print(f\"Training with C = {C}\")\n",
    "    \n",
    "    # Initialize the Logistic Regression classifier\n",
    "    classifier = LogisticRegression(random_state=0, C=C, max_iter=1000, verbose=0)\n",
    "    \n",
    "    # Train the classifier on the training features\n",
    "    classifier.fit(train_features, train_labels)\n",
    "    \n",
    "    # Evaluate the classifier on the validation set\n",
    "    val_predictions = classifier.predict(val_features)\n",
    "    val_accuracy = np.mean((val_labels == val_predictions).astype(float)) * 100.\n",
    "    print(f\"Validation Accuracy = {val_accuracy:.3f}%\")\n",
    "    \n",
    "    # Track the best C value based on validation accuracy\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C value: {best_C} with validation accuracy of {best_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef5c81",
   "metadata": {},
   "source": [
    "Some C values output the \"ConvergenceWarning: lbfgs failed to converge (status=1):STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\".\n",
    "This project follows the original CLIP "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26721368",
   "metadata": {},
   "source": [
    "Test accuracy with the best L2 Regularization value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fb4428c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 96.790%\n"
     ]
    }
   ],
   "source": [
    "# Train the classifier on the entire training dataset with the best C\n",
    "final_classifier = LogisticRegression(random_state=0, C=best_C, max_iter=1000, verbose=1)\n",
    "final_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_predictions = final_classifier.predict(test_features)\n",
    "test_accuracy = np.mean((test_labels == test_predictions).astype(float)) * 100.\n",
    "print(f\"Test Accuracy = {test_accuracy:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc670814",
   "metadata": {},
   "source": [
    "### Zero-shot Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c865b13e",
   "metadata": {},
   "source": [
    "Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a713a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Zero-shot learning\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "\n",
    "# Prepare text inputs (text descriptions for the CIFAR-10 classes)\n",
    "text_inputs = torch.cat([tokenizer(f\"a photo of a {c}\") for c in test_data.classes]).to(device)\n",
    "text_features = model.encode_text(text_inputs)\n",
    "text_features /= text_features.norm(dim=-1, keepdim=True)  # Normalize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7686ae61",
   "metadata": {},
   "source": [
    "Zero-shot evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c03a22c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.92s/it]\n"
     ]
    }
   ],
   "source": [
    "correct_top1 = 0\n",
    "correct_top5 = 0\n",
    "total = len(test_data)\n",
    "\n",
    "# Loop through all the test samples in batches\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(DataLoader(test_data, batch_size=batch_size)):\n",
    "        image_features = model.encode_image(images.to(device))\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)  # Normalize\n",
    "\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "        # Get the top 5 predictions for each image in the batch\n",
    "        values, indices = similarity.topk(5, dim=-1)  # Get top 5 predictions for all images in the batch\n",
    "\n",
    "        # Calculate top-1 and top-5 accuracy for each image in the batch\n",
    "        for i in range(len(labels)):\n",
    "            # Check if the true class is in the top 1 prediction\n",
    "            if indices[i, 0].item() == labels[i]:\n",
    "                correct_top1 += 1\n",
    "\n",
    "            # Check if the true class is in the top 5 predictions\n",
    "            if labels[i] in indices[i].tolist():\n",
    "                correct_top5 += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae008e",
   "metadata": {},
   "source": [
    "Calculate Top-1 and Top-5 Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f016058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 accuracy: 93.65%\n",
      "Top-5 accuracy: 99.83%\n"
     ]
    }
   ],
   "source": [
    "# Calculate top-1 and top-5 accuracy\n",
    "top1_accuracy = correct_top1 / total * 100\n",
    "top5_accuracy = correct_top5 / total * 100\n",
    "\n",
    "print(f\"Top-1 accuracy: {top1_accuracy:.2f}%\")\n",
    "print(f\"Top-5 accuracy: {top5_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e3253",
   "metadata": {},
   "source": [
    "### Influence of Class name on Zero-shot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2c7accd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:09<00:00,  1.90s/it]\n",
      "100%|██████████| 5/5 [00:09<00:00,  2.00s/it]\n",
      "100%|██████████| 5/5 [00:10<00:00,  2.04s/it]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.90s/it]\n",
      "100%|██████████| 5/5 [00:09<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text variation: Simple description\n",
      "  Top-1 accuracy: 93.65%\n",
      "  Top-5 accuracy: 99.83%\n",
      "Text variation: Image description\n",
      "  Top-1 accuracy: 93.62%\n",
      "  Top-5 accuracy: 99.83%\n",
      "Text variation: Detailed description\n",
      "  Top-1 accuracy: 94.14%\n",
      "  Top-5 accuracy: 99.77%\n",
      "Text variation: Sentence structure 1\n",
      "  Top-1 accuracy: 93.39%\n",
      "  Top-5 accuracy: 99.79%\n",
      "Text variation: Sentence structure 2\n",
      "  Top-1 accuracy: 93.66%\n",
      "  Top-5 accuracy: 99.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define multiple variations of text descriptions for CIFAR-10 classes\n",
    "text_variations = [\n",
    "    # Simple description\n",
    "    (\"Simple description\", lambda c: f\"a photo of a {c}\"),      # 93.65%\n",
    "    (\"Image description\", lambda c: f\"an image of a {c}\"),      # 93.62%\n",
    "\n",
    "    # Detailed description\n",
    "    # (\"Detailed description\", lambda c: f\"a detailed photo of a {c} with fine details\"),       92.94%\n",
    "    (\"Detailed description\", lambda c: f\"a photo with the main subject of a {c}\"),              # 94.14%\n",
    "\n",
    "\n",
    "    # Adding adjectives\n",
    "    # (\"Large description\", lambda c: f\"a large photo of a {c}\"),       91.98%\n",
    "    # (\"Small description\", lambda c: f\"a small photo of a {c}\"),       93.06%\n",
    "\n",
    "    # Sentence structure variations\n",
    "    (\"Sentence structure 1\", lambda c: f\"this is a photo of a {c}\"),        # 93.39%\n",
    "    (\"Sentence structure 2\", lambda c: f\"a beautiful photo of a {c}\"),      # 93.66%\n",
    "]\n",
    "\n",
    "accuracies = {}\n",
    "\n",
    "# Iterate over the different text input variations\n",
    "for variation_name, description in text_variations:\n",
    "    # Prepare text inputs\n",
    "    text_inputs = torch.cat([tokenizer(description(c)) for c in test_data.classes]).to(device)\n",
    "    text_features = model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)  # Normalize\n",
    "\n",
    "    correct_top1 = 0\n",
    "    correct_top5 = 0\n",
    "    total = len(test_data)\n",
    "\n",
    "    # Loop through all the test samples in batches\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(DataLoader(test_data, batch_size=batch_size)):\n",
    "            image_features = model.encode_image(images.to(device))\n",
    "            image_features /= image_features.norm(dim=-1, keepdim=True)  # Normalize\n",
    "\n",
    "            similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "            # Get the top 5 predictions for each image in the batch\n",
    "            values, indices = similarity.topk(5, dim=-1)\n",
    "\n",
    "            # Calculate top-1 and top-5 accuracy for each image in the batch\n",
    "            for i in range(len(labels)):\n",
    "                # Check if the true class is in the top 1 prediction\n",
    "                if indices[i, 0].item() == labels[i]:\n",
    "                    correct_top1 += 1\n",
    "\n",
    "                # Check if the true class is in the top 5 predictions\n",
    "                if labels[i] in indices[i].tolist():\n",
    "                    correct_top5 += 1\n",
    "\n",
    "    # Calculate top-1 and top-5 accuracy\n",
    "    top1_accuracy = correct_top1 / total * 100\n",
    "    top5_accuracy = correct_top5 / total * 100\n",
    "\n",
    "    # Store the results for this variation\n",
    "    accuracies[variation_name] = (top1_accuracy, top5_accuracy)\n",
    "\n",
    "# Output the accuracies for all variations\n",
    "for variation_name, (top1, top5) in accuracies.items():\n",
    "    print(f\"Text variation: {variation_name}\")\n",
    "    print(f\"  Top-1 accuracy: {top1:.2f}%\")\n",
    "    print(f\"  Top-5 accuracy: {top5:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open_clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
